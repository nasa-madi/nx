services:

  #-----------------------------
  # API SERVICE
  #-----------------------------
  # This is the real API available at port 3030.  It builds an image 
  # for the top level docker-compose and may not be the same image 
  # as built under the /api folder directly
  api:
    build: ${PWD}/ # must be relative to the compose file
    environment:
      - NODE_ENV=development
      - MIGRATION=true
      - SEED=true
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    ports:
      - 3030:3030
    networks:
      - madi
    volumes:
      - ${PWD}/test/contracts/plugin-loader/plugins/devGetTime:/app/plugins/devGetTime # Only used for plugin-loader tests
      - ./${CONTRACT_TYPE}/${CONTRACT_TYPE}.yml:/app/config/local.yml
      - ${PWD}/test/contracts/credentials.json:/app/credentials.json
    depends_on:
      database:
        condition: service_healthy
      # storage: 
      #   condition: service_healthy
      # parser: 
      #   condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -s -o /dev/null -w \"%{http_code}\" http://localhost:3030 | grep -q \"404\" && exit 0 || exit 1"]
      interval: 60s
      timeout: 5s
      start_period: 60s
      start_interval: 5s
      retries: 5

  #-----------------------------
  # DATABASE SERVICE
  #-----------------------------
  # This is the postgres docker DB available at port 35432 for local usage.
  # When referencing the db from a compose container, use database:5432
  # When referencing the db from an external process, use localhost:35432
  database:
    image: "ankane/pgvector"
    environment:
      - POSTGRES_USER=unicorn_user
      - POSTGRES_PASSWORD=magical_password
      - POSTGRES_DB=rainbow_database
    # volumes:  # Commented out so that every DB is migrated and seeded fresh.
    #   - database-data:/var/lib/postgresql/data/
    ports:
      - "5432:5432"
    networks:
      - madi
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U unicorn_user -d rainbow_database"]
      interval: 5s
      timeout: 5s
      retries: 5


  #-----------------------------
  # CLOUD STORAGE MOCK SERVICE
  #-----------------------------
  # This mocks out a Google Cloud Storage server so that local testing
  # can be done with a GCS Bucket library.
  storage:
    image: nasamadi/madi-storage-gcs-emulator:latest
    environment:
      - PORT=9023
      - STORAGE_BASE=./api
      - STORAGE_DIR=./uploads
    ports:
      - "9023:9023"
    volumes:
      - ${PWD}/.uploads/preload:/app/api/preload
      # - ${PWD}/.uploads/mounted:/app/api/uploads
    networks:
      - madi
    entrypoint: >
      sh -c "
          cp -r /app/api/preload/* /app/api/uploads && 
          gcp-storage-emulator start
      "
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9023 | grep 'OK' || exit 1"]
      interval: 60s
      timeout: 5s
      retries: 5
  
  #-----------------------------
  # PARSER SERVICE
  #-----------------------------
  # This creates a parsers services based on nlm-ingestor and Apache Tika
  parser:
    image: nasamadi/madi-parsers-nlm:latest
    ports:
      - 5001:5001
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:5001 || exit 1"]
      interval: 60s
      timeout: 5s
      start_period: 30s
      start_interval: 1s
      retries: 5
    networks:
      - madi


  newman:
    image: postman/newman:ubuntu
    environment:
      - CONTRACT_TYPE=${CONTRACT_TYPE}
    volumes:
      - ${PWD}/test/contracts/contract.collection.json:/etc/newman/contract.collection.json
      - ${PWD}/test/contracts/files:/etc/newman/files
      - ${PWD}/test/contracts/entrypoint.sh:/etc/newman/entrypoint.sh
      - ${PWD}/test/contracts/conversion.js:/etc/newman/conversion.js
    networks:
      - madi
    depends_on:
      parser:
        condition: service_healthy
      api:
        condition: service_healthy
    entrypoint: ["/bin/sh", "entrypoint.sh"]

networks:
  madi:

volumes:
  database-data:
  vss-data:
